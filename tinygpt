{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df27a636",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-07-28T15:01:22.086824Z",
     "iopub.status.busy": "2024-07-28T15:01:22.086144Z",
     "iopub.status.idle": "2024-07-28T15:01:34.190241Z",
     "shell.execute_reply": "2024-07-28T15:01:34.189247Z"
    },
    "papermill": {
     "duration": 12.114065,
     "end_time": "2024-07-28T15:01:34.192607",
     "exception": false,
     "start_time": "2024-07-28T15:01:22.078542",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, MultiHeadAttention, Embedding, Add, Dropout, LayerNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import bisect\n",
    "import re\n",
    "import math\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b85e4692",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T15:01:34.206631Z",
     "iopub.status.busy": "2024-07-28T15:01:34.206085Z",
     "iopub.status.idle": "2024-07-28T15:01:34.212940Z",
     "shell.execute_reply": "2024-07-28T15:01:34.212147Z"
    },
    "papermill": {
     "duration": 0.015989,
     "end_time": "2024-07-28T15:01:34.214884",
     "exception": false,
     "start_time": "2024-07-28T15:01:34.198895",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# My tokenkization\\nfrom nltk.corpus import brown\\n\\nfor file in brown.fileids():\\n    clean_file = re.sub(r\\'/[^\\\\s]+\\', \\' \\', brown.raw(file))\\n    dataset += clean_file + \"\\n\" # Concatenate all the files together\\n\\ndataset = re.sub(r\\'\\\\s+\\', \\' \\', dataset)\\nlen(dataset) # Number of characters\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# My tokenkization\n",
    "from nltk.corpus import brown\n",
    "\n",
    "for file in brown.fileids():\n",
    "    clean_file = re.sub(r'/[^\\s]+', ' ', brown.raw(file))\n",
    "    dataset += clean_file + \"\\n\" # Concatenate all the files together\n",
    "\n",
    "dataset = re.sub(r'\\s+', ' ', dataset)\n",
    "len(dataset) # Number of characters\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "433bef4c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T15:01:34.228118Z",
     "iopub.status.busy": "2024-07-28T15:01:34.227777Z",
     "iopub.status.idle": "2024-07-28T15:01:35.686820Z",
     "shell.execute_reply": "2024-07-28T15:01:35.686030Z"
    },
    "papermill": {
     "duration": 1.468243,
     "end_time": "2024-07-28T15:01:35.689073",
     "exception": false,
     "start_time": "2024-07-28T15:01:34.220830",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataset = \"\"\n",
    "\n",
    "texts = pd.read_csv('/kaggle/input/brown.csv')[\"tokenized_text\"]\n",
    "for text in texts:\n",
    "    dataset += text\n",
    "# Separate the punctuation from the words by a space\n",
    "dataset = re.sub('[^a-zA-Z0-9\\s]+', lambda x: x.group(0)[0] , dataset)    \n",
    "dataset = re.sub(r'\\s+', ' ', dataset)\n",
    "\n",
    "dataset = dataset.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aabf75ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T15:01:35.705505Z",
     "iopub.status.busy": "2024-07-28T15:01:35.705202Z",
     "iopub.status.idle": "2024-07-28T15:01:35.809365Z",
     "shell.execute_reply": "2024-07-28T15:01:35.808459Z"
    },
    "papermill": {
     "duration": 0.114815,
     "end_time": "2024-07-28T15:01:35.811908",
     "exception": false,
     "start_time": "2024-07-28T15:01:35.697093",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61264"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = sorted(set(dataset))\n",
    "vocab_size = len(vocab) + 2\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e62349ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T15:01:35.836570Z",
     "iopub.status.busy": "2024-07-28T15:01:35.836243Z",
     "iopub.status.idle": "2024-07-28T15:01:36.350279Z",
     "shell.execute_reply": "2024-07-28T15:01:36.349324Z"
    },
    "papermill": {
     "duration": 0.523438,
     "end_time": "2024-07-28T15:01:36.352408",
     "exception": false,
     "start_time": "2024-07-28T15:01:35.828970",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "830"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = \" \".join(dataset).split(\".\")\n",
    "sentences = [s.split() for s in sentences if len(s.split())>0]\n",
    "max_length = max([len(s) for s in sentences])\n",
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd5d5137",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T15:01:36.366305Z",
     "iopub.status.busy": "2024-07-28T15:01:36.366014Z",
     "iopub.status.idle": "2024-07-28T15:01:36.395699Z",
     "shell.execute_reply": "2024-07-28T15:01:36.394849Z"
    },
    "papermill": {
     "duration": 0.038662,
     "end_time": "2024-07-28T15:01:36.397471",
     "exception": false,
     "start_time": "2024-07-28T15:01:36.358809",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.899629529231046 15.372308871704446 118.66599999999744\n"
     ]
    }
   ],
   "source": [
    "lengths = [len(s) for s in sentences]\n",
    "print(np.mean(lengths), np.std(lengths), np.quantile(lengths, .999))\n",
    "\n",
    "# 1 in 1000 sentences exceed 128 so 128 it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2994e283",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T15:01:36.411244Z",
     "iopub.status.busy": "2024-07-28T15:01:36.410949Z",
     "iopub.status.idle": "2024-07-28T15:01:38.228088Z",
     "shell.execute_reply": "2024-07-28T15:01:38.227301Z"
    },
    "papermill": {
     "duration": 1.826757,
     "end_time": "2024-07-28T15:01:38.230606",
     "exception": false,
     "start_time": "2024-07-28T15:01:36.403849",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sentence_length = 128 # 2 ** math.ceil(math.log2(max_length)) if we want to\n",
    "# include every sentence. But truncating 1 in 1000 for 8x memory saving seems\n",
    "# obvious.\n",
    "pad_id = 0\n",
    "start_id = 1\n",
    "\n",
    "point = bisect.bisect_left(vocab, '.') + 2\n",
    "dataset = np.zeros((len(sentences),  sentence_length + 1), dtype = np.float32) + pad_id\n",
    "\n",
    "for i, sentence in enumerate(sentences):\n",
    "    dataset[i, :min(len(sentence) + 2, sentence_length + 1)] = np.array([start_id] + [bisect.bisect_left(vocab, word) + 2 for word in sentence][:sentence_length - 1] + [point], dtype = np.float32)\n",
    "\n",
    "vocab = [\"<PAD>\", \"<S>\"] + vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e421224",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T15:01:38.244926Z",
     "iopub.status.busy": "2024-07-28T15:01:38.244619Z",
     "iopub.status.idle": "2024-07-28T15:01:38.250055Z",
     "shell.execute_reply": "2024-07-28T15:01:38.249177Z"
    },
    "papermill": {
     "duration": 0.014827,
     "end_time": "2024-07-28T15:01:38.252058",
     "exception": false,
     "start_time": "2024-07-28T15:01:38.237231",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FeedForward(tf.keras.Model):\n",
    "    def __init__(self, emb_dim, units):\n",
    "        super().__init__()\n",
    "        self.dense1 = Dense(units, activation = \"relu\")\n",
    "        self.dense2 = Dense(emb_dim)\n",
    "        \n",
    "    def call(self, x):\n",
    "        x = self.dense1(x)\n",
    "        out = self.dense2(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4f09ca3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T15:01:38.266127Z",
     "iopub.status.busy": "2024-07-28T15:01:38.265646Z",
     "iopub.status.idle": "2024-07-28T15:01:38.273136Z",
     "shell.execute_reply": "2024-07-28T15:01:38.272283Z"
    },
    "papermill": {
     "duration": 0.016694,
     "end_time": "2024-07-28T15:01:38.275039",
     "exception": false,
     "start_time": "2024-07-28T15:01:38.258345",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, n_heads = 8, emb_dim = 512, units = 2048, dropout = .1):\n",
    "        super().__init__()\n",
    "        self.mha = MultiHeadAttention(n_heads, emb_dim//n_heads)\n",
    "        self.dropout1 =  Dropout(dropout)\n",
    "        self.ln1 = LayerNormalization()\n",
    "        \n",
    "        self.ffn = FeedForward(emb_dim, units)\n",
    "        self.dropout2 =  Dropout(dropout)\n",
    "        self.ln2 = LayerNormalization()\n",
    "        \n",
    "    def call(self, x, training):\n",
    "        # Masked multi-head self-attention\n",
    "        # The mask for the padding is problematic to implement here and it's more \n",
    "        # convenient to mask the loss function and we just use the look-ahead mask here.\n",
    "        x1 = self.mha(x, x, x, use_causal_mask = True)\n",
    "        x1 = self.dropout1(x1, training = training)\n",
    "        x = self.ln1(x1 + x)\n",
    "        \n",
    "        x2 = self.ffn(x)\n",
    "        x2 = self.dropout2(x2, training = training)\n",
    "        x = self.ln2(x + x2)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4900d767",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T15:01:38.288946Z",
     "iopub.status.busy": "2024-07-28T15:01:38.288636Z",
     "iopub.status.idle": "2024-07-28T15:01:38.296140Z",
     "shell.execute_reply": "2024-07-28T15:01:38.295310Z"
    },
    "papermill": {
     "duration": 0.01673,
     "end_time": "2024-07-28T15:01:38.298053",
     "exception": false,
     "start_time": "2024-07-28T15:01:38.281323",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, sentence_length = 256, n = 6, n_heads = 8, emb_dim = 512, units = 2048, dropout = .1):\n",
    "        super().__init__()\n",
    "        # Embedding layer\n",
    "        self.embedding = Embedding(vocab_size, emb_dim, input_length = sentence_length)\n",
    "        # Positional encoding\n",
    "        self.pos_encode = Add()\n",
    "        self.decoder_stack = [Decoder(n_heads, emb_dim, units, dropout) for _ in range(n)]\n",
    "        self.linear = Dense(vocab_size, activation = tf.nn.log_softmax)\n",
    "        \n",
    "    def call(self, x, training):\n",
    "        \n",
    "        x = self.embedding(x)\n",
    "        x = self.pos_encode([x, pos_encoding])\n",
    "        \n",
    "        for decoder in self.decoder_stack:\n",
    "            x = decoder(x, training)\n",
    "        \n",
    "        out = self.linear(x)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f818d0c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T15:01:38.312941Z",
     "iopub.status.busy": "2024-07-28T15:01:38.312688Z",
     "iopub.status.idle": "2024-07-28T15:01:38.318494Z",
     "shell.execute_reply": "2024-07-28T15:01:38.317693Z"
    },
    "papermill": {
     "duration": 0.015663,
     "end_time": "2024-07-28T15:01:38.320341",
     "exception": false,
     "start_time": "2024-07-28T15:01:38.304678",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# For a generative model, label smoothing simply hurts perplexity which is what we care \n",
    "# about most. \n",
    "epsilon  = 0.1\n",
    "\n",
    "def masked_loss(label, pred, pad_id = 0):\n",
    "    mask = label != pad_id\n",
    "    \n",
    "    y = tf.one_hot(tf.cast(label, tf.int32), vocab_size, axis = -1)\n",
    "    loss_object = tf.keras.losses.CategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none', label_smoothing = epsilon)\n",
    "    loss = loss_object(y, pred)\n",
    "    \n",
    "    mask = tf.cast(mask, dtype=loss.dtype)\n",
    "    loss *= mask\n",
    "\n",
    "    loss = tf.reduce_sum(loss)/tf.reduce_sum(mask)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ec9cf3e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T15:01:38.334136Z",
     "iopub.status.busy": "2024-07-28T15:01:38.333600Z",
     "iopub.status.idle": "2024-07-28T15:01:38.339678Z",
     "shell.execute_reply": "2024-07-28T15:01:38.338929Z"
    },
    "papermill": {
     "duration": 0.014929,
     "end_time": "2024-07-28T15:01:38.341502",
     "exception": false,
     "start_time": "2024-07-28T15:01:38.326573",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TransformerLearningRateSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, initial_learning_rate, warmup_steps):\n",
    "        self.initial_learning_rate = initial_learning_rate\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def __call__(self, step):\n",
    "        x1 = tf.math.pow(10 / tf.math.sqrt(tf.cast(step, tf.float32)), tf.constant([-0.5]))\n",
    "        x2 =  tf.cast(step, tf.float32) * tf.constant([10 * warmup_steps**-1.5])\n",
    "        return self.initial_learning_rate * tf.math.minimum(x1, x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00339298",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T15:01:38.354895Z",
     "iopub.status.busy": "2024-07-28T15:01:38.354618Z",
     "iopub.status.idle": "2024-07-28T15:01:39.235641Z",
     "shell.execute_reply": "2024-07-28T15:01:39.234571Z"
    },
    "papermill": {
     "duration": 0.890078,
     "end_time": "2024-07-28T15:01:39.237745",
     "exception": false,
     "start_time": "2024-07-28T15:01:38.347667",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "emb_dim = 512\n",
    "n_heads = 8\n",
    "units = 2048\n",
    "n = 6\n",
    "dropout = 0.1\n",
    "# warmup_steps = 1000\n",
    "learning_rate = 1e-3\n",
    "# Using a different learning rate than the paper as they train for many more steps.\n",
    "#learning_rate_schedule = TransformerLearningRateSchedule(emb_dim**-.5, warmup_steps)\n",
    "optimizer = Adam(learning_rate, beta_1 = .9, beta_2 = .998, epsilon = 1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "615122bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T15:01:39.252966Z",
     "iopub.status.busy": "2024-07-28T15:01:39.252685Z",
     "iopub.status.idle": "2024-07-28T15:01:39.268212Z",
     "shell.execute_reply": "2024-07-28T15:01:39.267285Z"
    },
    "papermill": {
     "duration": 0.025487,
     "end_time": "2024-07-28T15:01:39.270094",
     "exception": false,
     "start_time": "2024-07-28T15:01:39.244607",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Positional encoding\n",
    "pos_encoding = np.zeros((sentence_length, emb_dim))\n",
    "pos = np.arange(sentence_length)[:, np.newaxis]\n",
    "even = np.arange(emb_dim, step = 2)[np.newaxis, :]\n",
    "pos_encoding[:, ::2] = np.sin(pos/10**(4*even/emb_dim))\n",
    "pos_encoding[:, 1::2] = np.cos(pos/10**(4*even/emb_dim))\n",
    "pos_encoding = pos_encoding[np.newaxis, :, :] # Adding the batch dimension\n",
    "pos_encoding = tf.cast(pos_encoding, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3149f573",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T15:01:39.283923Z",
     "iopub.status.busy": "2024-07-28T15:01:39.283622Z",
     "iopub.status.idle": "2024-07-28T15:01:40.393224Z",
     "shell.execute_reply": "2024-07-28T15:01:40.392281Z"
    },
    "papermill": {
     "duration": 1.118802,
     "end_time": "2024-07-28T15:01:40.395231",
     "exception": false,
     "start_time": "2024-07-28T15:01:39.276429",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       multiple                  31367168  \n",
      "                                                                 \n",
      " add (Add)                   multiple                  0         \n",
      "                                                                 \n",
      " decoder (Decoder)           multiple                  3152384   \n",
      "                                                                 \n",
      " decoder_1 (Decoder)         multiple                  3152384   \n",
      "                                                                 \n",
      " decoder_2 (Decoder)         multiple                  3152384   \n",
      "                                                                 \n",
      " decoder_3 (Decoder)         multiple                  3152384   \n",
      "                                                                 \n",
      " decoder_4 (Decoder)         multiple                  3152384   \n",
      "                                                                 \n",
      " decoder_5 (Decoder)         multiple                  3152384   \n",
      "                                                                 \n",
      " dense_12 (Dense)            multiple                  31428432  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 81709904 (311.70 MB)\n",
      "Trainable params: 81709904 (311.70 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Transformer(vocab_size, sentence_length, n, n_heads, emb_dim, units, dropout)\n",
    "model.compile(optimizer, masked_loss)\n",
    "model.build((None, sentence_length))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4993846e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T15:01:40.413482Z",
     "iopub.status.busy": "2024-07-28T15:01:40.413192Z",
     "iopub.status.idle": "2024-07-28T15:28:02.989025Z",
     "shell.execute_reply": "2024-07-28T15:28:02.988068Z"
    },
    "papermill": {
     "duration": 1582.972416,
     "end_time": "2024-07-28T15:28:03.376256",
     "exception": false,
     "start_time": "2024-07-28T15:01:40.403840",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1643/1643 [==============================] - 541s 318ms/step - loss: 7.7765 - val_loss: 10.5740\n",
      "Epoch 2/3\n",
      "1643/1643 [==============================] - 521s 317ms/step - loss: 7.6394 - val_loss: 10.4238\n",
      "Epoch 3/3\n",
      "1643/1643 [==============================] - 521s 317ms/step - loss: 7.6230 - val_loss: 10.2525\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "epochs = 3\n",
    "\n",
    "# X is simply the expected output shifted to the right with a <S> token at the beginning.\n",
    "history = model.fit(dataset[:, :-1], dataset[:, 1:], batch_size, epochs, validation_split = .05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "139d0e8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T15:28:04.155928Z",
     "iopub.status.busy": "2024-07-28T15:28:04.155543Z",
     "iopub.status.idle": "2024-07-28T15:28:04.540717Z",
     "shell.execute_reply": "2024-07-28T15:28:04.539866Z"
    },
    "papermill": {
     "duration": 0.778257,
     "end_time": "2024-07-28T15:28:04.542749",
     "exception": false,
     "start_time": "2024-07-28T15:28:03.764492",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylim(0, max(history.history['loss'] + history.history['val_loss']))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "af112184",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T15:28:05.370276Z",
     "iopub.status.busy": "2024-07-28T15:28:05.369888Z",
     "iopub.status.idle": "2024-07-28T15:28:05.545125Z",
     "shell.execute_reply": "2024-07-28T15:28:05.544242Z"
    },
    "papermill": {
     "duration": 0.615929,
     "end_time": "2024-07-28T15:28:05.547341",
     "exception": false,
     "start_time": "2024-07-28T15:28:04.931412",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Furthermore 0.0008294977596960962\n",
      ", 0.006127688102424145\n",
      "as 6.960728933336213e-05\n",
      "an 5.837332355440594e-05\n",
      "encouragement 2.62151297647506e-06\n",
      "to 0.00023054225312080234\n",
      "revisionist 1.338953211416083e-06\n",
      "thinking 6.111992206569994e-06\n",
      ", 0.006127696484327316\n",
      "it 0.00010067726543638855\n",
      "manifestly 2.2982026166573633e-06\n",
      "is 0.0003289782616775483\n",
      "fair 2.8721126454911428e-06\n",
      "to 0.00023054229677654803\n",
      "admit 2.7931657768931473e-06\n",
      "that 5.3558815125143155e-05\n",
      "any 3.1064566428540275e-05\n",
      "fraternity 1.4567207244908786e-06\n",
      "has 0.0001404856302542612\n",
      "a 0.00014548191393259913\n",
      "constitutional 2.6606876417645253e-06\n",
      "right 2.3691907699685544e-05\n",
      "to 0.00023054229677654803\n",
      "refuse 4.202745913062245e-06\n",
      "to 0.00023054232588037848\n",
      "accept 4.212816747894976e-06\n",
      "persons 1.0321157787984703e-05\n",
      "it 0.0001006772872642614\n",
      "dislikes 1.6629802530587767e-06\n",
      ". 0.0003429400676395744\n"
     ]
    }
   ],
   "source": [
    "# Examining the 1st example.\n",
    "x = dataset[0]\n",
    "am = tf.nn.softmax(model(tf.reshape(x[:-1], (1, sentence_length))), axis = -1)\n",
    "indices = map(int, x[1:])\n",
    "am = tf.reshape(am, (-1, vocab_size))\n",
    "probs = []\n",
    "for i, idx in enumerate(indices):\n",
    "    if idx == 0:\n",
    "        break\n",
    "    print(vocab[idx], float(am[i, idx]))\n",
    "    probs.append(float(am[i, idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "57970222",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T15:28:06.351724Z",
     "iopub.status.busy": "2024-07-28T15:28:06.351353Z",
     "iopub.status.idle": "2024-07-28T15:33:14.955777Z",
     "shell.execute_reply": "2024-07-28T15:33:14.954732Z"
    },
    "papermill": {
     "duration": 308.997595,
     "end_time": "2024-07-28T15:33:14.957991",
     "exception": false,
     "start_time": "2024-07-28T15:28:05.960396",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I He The The For Y It Oh And In He The He The When The The The For The Mercer In Richard's It She of He At He He With But It They He She In I The He He I'll He I The He He For There On The The He The The He Kennedy In Through The Dartmouth The The The It The He She More And But If He In It's She The Last I And He The He The It The Almost The But He Why The The He If Amy But A The The He They The I The This And The See It One He I This It He The He He The The I But It The The I But\n",
      "It The He He Our One The Finally In But This He Institut The I The I He A The The The The And She The In In She The When I After You It The H At The He The She It In She She I He The The One The The The The In The If If I The It They A The To The He The I Then The She A It If Peter Little The It , He As It They Gavin's It The The But The I So The The In The This There I He The He The S The The The The The For He According It A I He The I He But The She R The The In But\n",
      "The The He But If The Actually In The I In Then This It The To I He The The I Pesce The It He A Selkirk The In The This I His The He But All The He The But But I He His The It One The I He A It My The It The It I m*ym The Her Matamoras It The It I The A If The He It He There For The The The , The The I The He He She In He In During But The They The To They The There I The He This You'll The The He With The The The Then It The A The The But He The The But The He It The I The\n",
      "He He I The This So By The Many But If In He The According The The I So The I He He But Because The In But He But Institut I She The He Kennedy He He But In The By The He The An His The Then He The The It Such But He The The , But This But He He The The By The Recherche The In I He And He He The The I The The In A But , He The In The Of A The It The The He And There An The They 1 Under The The For If He The I The It In As The Such Memorial He As The He She The With Somehow But And The\n",
      "My I In It He The He It The For He He This A He Lubell Even Haney The Do She We When Peck His For The The If The The They Multnomah With , , He The We The A I I He The A But The The He The His The She It He He The Then But The That's We She I I She But Mrs At She Another It It The It He I But The He The In The He The The He In The The He I He But It But But The The For The The No The Without The He The He He Turnkey It The The Ironpants It A The The These She It Unfortunately There The They He\n",
      "The He The The The He The A The There He The The I He But The But He It It perish He For He His But The He I After At The He The Precious It The But The The It Then A He The There She The The The He He A It They The She The In He It The The The The Mr. On The As The The He No At But It This But They He The But , He It The The By He He The In He He You A He That The The The If I He He The The The The The It It He The The But The In It It A The The I He There It\n",
      "In But In There To A C He ? But No He Again Not The The This The The He The After The This I It The The The I The A D , All The The The The As The C In The He She In I Institut It The The They The There It She He She At The In He They The We The They He I 2 The The In And It There The He A He Maybe He There He The I Gas He The There The No A The The When It I The They One Board The There The It We The The I He Mrs But The I The This The The The The The I He He The He\n",
      "I Miss We The He But The It The She The I The It And The Both He The And The It Othon They He He And It He M The So The It The It The He It It I For In The This The But He For He All By I The The In He The And The The You At He In And It The He I The But S The The He It Then He He But I'd He Is escapist The The She If He He The The The Not Mrs There But As and , The He Richard's She The I The There Although For For The These The And Will Before In Once In The The It He He His You\n",
      "The I The The The A Thomas The I In When In It When The He At The The But The The He At He The The Indeed The It And He The Each It The I I The The When She The The We're Sherman I He When I modern It This The The The Mrs He After The The And In A This Still The A Skyros It He I The The The It But The The The But She One He The The The I The It For It The The He The The Yet He A Don't The D This S The The In You The The He The Now The He And The It He On The Yes Whom In He I They\n",
      "She Some It The He In How How Again They She A When The In He So The Mrs We This The Institut The The All The The The Mr. As The Mr. Therefore He In The Even They He Teter It His The He This The The He The And The His He Skyros There The I've The He This He The Some The The This He there But He It But There He The The The As He But He Or The She There Well But He's The Without In But Is He If The These The I A The The It It I To The But The The He He He Then I On The This In The It Who The I The L Henderson\n",
      "In The And The This Mrs A For He A He She The This Through He The This I But He The I Mr. The The Institut Their The In The The She It In The I The This He And The The But The The I The Today The fact The During The Both In That The But But The It He He He And The The The The It We The The This The He The He They A It The N He When Sixteenth No The The The The She The The At This She The The The If There The There He The The A It This There It But If As He It The The The The This I My 8 A The\n",
      "The You It She When This On The He Another He Then The The 1 The He If The But He The The The But If Once I I H The My We I The When The They He Not The If Morgan For Mrs And The Truman The The This On In The A Waddell The If But The His He His The The The The If One And Outside If He This The , He The The One The He For She The At The It It After The He He C The The He It He It It He The The On He He The No Mommy He I Watson He She The He I These A I He The He Now The In Even\n",
      "The He The The A The The One Andrei I Don't It Morgan It It and A It The With He We His He There A He The There It If She He The He The The The But He This The The What The The The In I Here I In It The The They She Thus The But They This Ore. I The I , She The He In Nothing The The The It There The He He I A The Since For The He The This The The She The The And He Then I His The I Well Therefore And Thus The She The The The The That They My The He But The The He The This The The The The The We\n",
      "The In The The His In He A He The But The The He Morse Mr. The The For In She Certainly The I The He's They Use Responsibility It I He Then The The Henderson And But His He The And Why I The The It He I She The He When The The The But long The They He It The Watson But No The It The The The There The The The The Everything The The The The He If There The This The I Certainly But The The The The No He In I It Another Cox The Much The The She The In He He Finally It The The The In The The The The When I She The Resolves But I He\n",
      "It There The In I I Well But The For The If She The The He The She The He The There We Everyone I He The He The Because He The A The The The All The But A If Then But The So To This We're This This The It The You In To This The He I I For I The But The He S I The But The When Thom This 8 He He The The I I He I I The Now She The Thank You He The The Then In But Because The The This Our The It The He The I The They She She In I He The The Lemuel He The In The The He She The A The\n",
      "When A actors The The She The These There His The Its He 7 He In The It A During The He It This She He The He The I The He He But The But This The The The The During That The All 22 Money He The The The The That His The The m*ym The But The From No He The I The His The The You The They The The Shires And The The This And One But The These I I The The In The The , The If The He In In A A The The He I I The I Dr. And Quiet This I He The The A The If She Here This Thing It He And The I They\n",
      "The The He I In So The She A Where The The The The He As She The The In For The It The The These This The But The The What But you She You He It But The I The It The There In The Her The The A There And Thus One The He She The She But He It I It Both Here They I But In A The He The Under Since The An Well Last It You The 4 He In The The The The He He I In The It We She He The One I His And The The vividly In A There The On I He He The Why His A But This I The The These The The\n",
      "This A Thus It The A But But He The He And The The The Measurements You're There He He The He The The He To It He This I The In The She For There In The The First Thomas Eisenhower You He I The They In In It If The The In The The I If I It If He He The He The The This And But What's In She I 8 The It A She As The The While It In I His We It The But The The I A He He It He It And It He He This He So There It I You The But But The D The He We I The The The I A The He That\n",
      "The And Peter But This The The The He I The I There The This If He For They She In The 4 This And If He And You The He I He 035 His The There As The After That This He In He It The He A The Contacts The The The In The The And The I It He He The And It There He That To He But We I The It The It It Some The In The His He The The It New Get He The The She Taylor He He But But The I The In He Then It The That The This The I The The I I The 1 It I The He He A He You The He\n",
      "The This Well The The The The Where The He He Of It My The It But But She The The The The The The He The , The The He This This The In Roberto He The He A Equate I The He Notte He With The The They It His The The The But And They The The It The And He The In One I It The For The 8 He The The The When He The The He At When One Today The He The A During The How S No The A At The It When That A They It As We The A He These You The She The It He It The He The A A In Here The But m*ym\n",
      "The He The The It It He But He The They The The I It It The The The The The She The But I The The The The , It He The We It And Your The I And A I It The At I The He And And Once I His My He The It For You It After His I But That His He I D This The But She He The I The The And It A Well And The And The The He There The This The Outside The At Sansom He The The But The He It His Other The If I The The The I The It I The Reading The The It In For Go The I This The He\n",
      "The In In This He And The It I I He This The From The But Don't He He I For I've The It The Sure I A In He Then He The He The He So There I The I People The The She He The If Again Miss At The When They Speaking And The What That When The He I The There If But The She The This It It We Sherman It's The It The The He The He The The In The He The But Then The One These He But I The The The And A Some But They The The I In They In He His This He His The But He For I He It The It If He A\n",
      "But He The It The I He He The In He The The Louise On The He But The The She A The For The And The It He The She The And She He I The He It And I If Now He He He The This For All If She The Furthermore He This This The It The The He The He A The A The , This In I But I All These The The A I The It The He The When The The But The The The He was The In He Institut He He I In In He The Among Pat When The There All 3 He For A A Histories The I When She There and It He They recoilless Then\n",
      "And It I That He's In And The The This But He Then These The The He But She He He This The For The Liston You The The The The This But Salt This What For If They His I In The At This The He A The In The There Get The The You You At The The He The Bonnor And The The The He We But Thus He He For The I I It The This Show He The The The 8 I The This After He You're The He He It He He More The There A It The Where He The And I He It Scotty The A It And The If And The Regiment He The Familism Certainly The It The\n",
      "I The He A There I The They The The It The The A He These A He He He , It The The The The The Then The The I He She A and But But And The The If I I I The A In He The The The It The The The It She The The He For Shires A He The He A A It The Yet There In It That In The It The For It He He For He The The A He It A He Now In The He I The I The The It If It s'accuse The The He C The 3 Where To The It She I Again , His This When The The The The The It\n"
     ]
    }
   ],
   "source": [
    "def softmax(logits, axis = -1):\n",
    "    e = np.exp(logits)\n",
    "    return e/np.sum(e, axis = axis)\n",
    "\n",
    "def sample(n = 10, temperature = .7):\n",
    "    for _ in range(n):\n",
    "        x = np.zeros((sentence_length + 1)) \n",
    "        # The first token is <S> which is irrelevant to the output.\n",
    "        x[0] = 1 # I could've used one-hot but making a sentence with one-hot seems weird. \n",
    "        i = 0\n",
    "        choices = []\n",
    "        choice = 0\n",
    "        indices = list(range(vocab_size))\n",
    "        \n",
    "        while choice != point and i < sentence_length:\n",
    "            out = np.ravel(model(x[:-1].reshape(1, sentence_length))[0, i])\n",
    "            # output shape is (batch_size, sentence_length, vocab_size)\n",
    "            probs = softmax(out / temperature, axis = -1)\n",
    "            choice = np.random.choice(indices, p = probs)\n",
    "            i = i+1\n",
    "            x[i] = choice\n",
    "            choices.append(choice)\n",
    "\n",
    "        sample = \" \".join(map(lambda x : vocab[x], choices))\n",
    "        print(sample)\n",
    "\n",
    "sample(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "799ca5ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T15:33:15.763977Z",
     "iopub.status.busy": "2024-07-28T15:33:15.763614Z",
     "iopub.status.idle": "2024-07-28T15:33:15.767671Z",
     "shell.execute_reply": "2024-07-28T15:33:15.766866Z"
    },
    "papermill": {
     "duration": 0.41458,
     "end_time": "2024-07-28T15:33:15.769611",
     "exception": false,
     "start_time": "2024-07-28T15:33:15.355031",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model.save(\"GPT.keras\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 2058,
     "sourceId": 131078,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30616,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1920.444134,
   "end_time": "2024-07-28T15:33:19.183562",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-07-28T15:01:18.739428",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
